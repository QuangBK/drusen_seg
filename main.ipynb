{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import pickle\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from unet import UNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose,\n",
    "    RandomCrop, Normalize, Resize\n",
    ")\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show(img):\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "niter=10\n",
    "outf='./saved_model/'\n",
    "\n",
    "IS_TRAINING = True\n",
    "n_channel = 3\n",
    "n_disc = 16\n",
    "n_gen = 64\n",
    "n_encode = 64\n",
    "n_l = 10\n",
    "n_z = 50\n",
    "img_size = 128\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "batchSize = 32\n",
    "use_cuda = torch.cuda.is_available()\n",
    "n_age = int(n_z/n_l)\n",
    "n_gender = int(n_z/2)\n",
    "\n",
    "n_class_age = 6\n",
    "n_repeat = 2\n",
    "\n",
    "PATH_DATA_TRAIN = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/patch_data_train_DeepLab/'\n",
    "PATH_DATA_TEST = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/patch_data_test_DeepLab/'\n",
    "\n",
    "PATH_DATA_MASKPRED_TRAIN = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/patch_data_mask_pred_train_DeepLab/'\n",
    "PATH_DATA_MASKPRED_TEST = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/patch_data_mask_pred_test_DeepLab/'\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10913\n",
      "10913 1087\n"
     ]
    }
   ],
   "source": [
    "list_paths_img_train = glob.glob(PATH_DATA_TRAIN + '*.jpg')\n",
    "list_paths_mask_train = [x.split('.')[0] + '.labels.tif' for x in list_paths_img_train]\n",
    "   \n",
    "print (len(list_paths_img_train))\n",
    "\n",
    "list_paths_img_test = glob.glob(PATH_DATA_TEST + '*.jpg')\n",
    "list_paths_mask_test = [x.split('.')[0] + '.labels.tif' for x in list_paths_img_test]\n",
    "   \n",
    "print (len(list_paths_img_train), len(list_paths_img_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAug:\n",
    "    def __init__(self, aug):\n",
    "        self.aug=aug\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.aug(image=img)['image']\n",
    "        return img\n",
    "\n",
    "class FundusDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, PATH_IMG, PATH_MASK, PATH_DATA_MASKPRED, transform=None, transform_torch=None, toTensor=None, train_transform_torch_mask_pred=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "#         self.root_dir = root_dir\n",
    "           \n",
    "#         self.df_paired = df_paired.loc[df_paired['train'] == train]\n",
    "        self.PATH_IMG = PATH_IMG\n",
    "        self.PATH_MASK = PATH_MASK\n",
    "        self.PATH_DATA_MASKPRED = PATH_DATA_MASKPRED\n",
    "        self.ToTensor = toTensor\n",
    "        self.transform = transform\n",
    "        self.transform_torch = transform_torch\n",
    "        self.train_transform_torch_mask_pred = train_transform_torch_mask_pred\n",
    "\n",
    "    def __len__(self):\n",
    "#         return 100\n",
    "        return len(self.PATH_IMG)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name_temp = self.PATH_IMG[idx].split('/')[-1]\n",
    "        image = cv2.imread(self.PATH_IMG[idx])\n",
    "        mask = cv2.imread(self.PATH_MASK[idx],0)\n",
    "        mask = np.where(mask > 0, 1., 0.)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "        mask_pred = cv2.imread(self.PATH_DATA_MASKPRED + file_name_temp,0)\n",
    "        mask_pred = np.expand_dims(mask_pred, axis=-1)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)   \n",
    "        \n",
    "        if self.transform:\n",
    "            img_auged = self.transform(image=image, mask=mask, mask_pred=mask_pred)\n",
    "            image = img_auged['image']\n",
    "            mask = img_auged['mask']\n",
    "            mask_pred = img_auged['mask_pred']\n",
    "            image = self.transform_torch(image)\n",
    "\n",
    "            mask = self.ToTensor(mask).float()\n",
    "            mask_pred = self.train_transform_torch_mask_pred(mask_pred)\n",
    "        sample = {'image': image, 'mask': mask, 'mask_pred': mask_pred, 'id': file_name_temp}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "train_album = Compose([\n",
    "    Resize(int(IMG_HEIGHT*1.), int(IMG_WIDTH*1.)), \n",
    "    RandomCrop(IMG_HEIGHT, IMG_HEIGHT),\n",
    "    HorizontalFlip(),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=.75)\n",
    "], additional_targets = {'image0': 'image', 'mask_pred': 'mask'})\n",
    "\n",
    "train_transform_torch = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "train_transform_torch_mask_pred = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "test_album = Compose([\n",
    "    Resize(IMG_HEIGHT, IMG_WIDTH)\n",
    "], additional_targets = {'image0': 'image', 'mask_pred': 'mask'})\n",
    "\n",
    "test_transform_torch = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "train_dataset = FundusDataset(list_paths_img_train, list_paths_mask_train, PATH_DATA_MASKPRED_TRAIN, transform=train_album, transform_torch=train_transform_torch, \n",
    "                              toTensor=transforms.ToTensor(), train_transform_torch_mask_pred=train_transform_torch_mask_pred)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=batchSize, shuffle=True,\n",
    "                                             num_workers=2, drop_last = True)\n",
    "\n",
    "valid_dataset = FundusDataset(list_paths_img_test, list_paths_mask_test, PATH_DATA_MASKPRED_TEST, transform=test_album, transform_torch=test_transform_torch, \n",
    "                              toTensor=transforms.ToTensor(), train_transform_torch_mask_pred=train_transform_torch_mask_pred)\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                             batch_size=32, shuffle=False,\n",
    "                                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "#     net = UNet(n_channels=3, n_classes=1).cuda()\n",
    "    net = nn.DataParallel(UNet(n_channels=4, n_classes=1)).cuda()\n",
    "else:\n",
    "    net = UNet(n_channels=3, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerE = optim.Adam(net.parameters(),lr=0.01, betas=(0.9, 0.995))\n",
    "scheduler = StepLR(optimizerE, step_size=17, gamma=0.1)\n",
    "# optimizerE = optim.SGD(net.parameters(),lr=0.01, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\n",
    "def tversky(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_pos = y_true.view(-1)\n",
    "    y_pred_pos = y_pred.view(-1)\n",
    "    true_pos = (y_true_pos * y_pred_pos).sum()\n",
    "    false_neg = (y_true_pos * (1-y_pred_pos)).sum()\n",
    "    false_pos = ((1-y_true_pos)*y_pred_pos).sum()\n",
    "    alpha = 0.75\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky_loss(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.6\n",
    "#     return tf.keras.backend.pow((1-pt_1), gamma)\n",
    "    return (1-pt_1).pow(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "def dice_loss_np(input, target):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = input.reshape(-1)\n",
    "    tflat = target.reshape(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "# dice_loss = DiceLoss().to(device)\n",
    "focal_loss = FocalLoss().to(device)\n",
    "# bounary_loss = BoundaryLoss(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/341 [00:00<?, ?it/s]/home/quang/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 341/341 [00:40<00:00,  9.08it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.38it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 finished ! Loss: 0.449 | Loss_weight: 0.449 | sensivity: 0.661 | specitivity: 0.964| Dice score: 0.639\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.85it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.33it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 finished ! Loss: 0.425 | Loss_weight: 0.425 | sensivity: 0.731 | specitivity: 0.944| Dice score: 0.618\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.53it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.22it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 finished ! Loss: 0.407 | Loss_weight: 0.407 | sensivity: 0.697 | specitivity: 0.963| Dice score: 0.658\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.90it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.41it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 finished ! Loss: 0.390 | Loss_weight: 0.390 | sensivity: 0.663 | specitivity: 0.970| Dice score: 0.660\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.92it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.31it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 finished ! Loss: 0.381 | Loss_weight: 0.381 | sensivity: 0.755 | specitivity: 0.953| Dice score: 0.660\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.83it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.19it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 finished ! Loss: 0.378 | Loss_weight: 0.378 | sensivity: 0.723 | specitivity: 0.962| Dice score: 0.672\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.15it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.07it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 finished ! Loss: 0.374 | Loss_weight: 0.374 | sensivity: 0.648 | specitivity: 0.976| Dice score: 0.673\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.34it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.29it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 finished ! Loss: 0.374 | Loss_weight: 0.374 | sensivity: 0.735 | specitivity: 0.959| Dice score: 0.669\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.64it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.27it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 finished ! Loss: 0.372 | Loss_weight: 0.372 | sensivity: 0.693 | specitivity: 0.971| Dice score: 0.683\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.69it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.32it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 finished ! Loss: 0.372 | Loss_weight: 0.372 | sensivity: 0.687 | specitivity: 0.971| Dice score: 0.682\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.89it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.07it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 finished ! Loss: 0.370 | Loss_weight: 0.370 | sensivity: 0.729 | specitivity: 0.960| Dice score: 0.667\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.65it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.37it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 finished ! Loss: 0.369 | Loss_weight: 0.369 | sensivity: 0.658 | specitivity: 0.976| Dice score: 0.683\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.64it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.33it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 finished ! Loss: 0.368 | Loss_weight: 0.368 | sensivity: 0.727 | specitivity: 0.962| Dice score: 0.674\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.86it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.20it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 finished ! Loss: 0.367 | Loss_weight: 0.367 | sensivity: 0.796 | specitivity: 0.938| Dice score: 0.638\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.76it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.08it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 finished ! Loss: 0.367 | Loss_weight: 0.367 | sensivity: 0.673 | specitivity: 0.974| Dice score: 0.684\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.45it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.21it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 finished ! Loss: 0.366 | Loss_weight: 0.366 | sensivity: 0.689 | specitivity: 0.972| Dice score: 0.687\n",
      "Current learning rate is: 0.01\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.84it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.32it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 finished ! Loss: 0.365 | Loss_weight: 0.365 | sensivity: 0.735 | specitivity: 0.961| Dice score: 0.676\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.87it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.16it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 finished ! Loss: 0.360 | Loss_weight: 0.360 | sensivity: 0.719 | specitivity: 0.966| Dice score: 0.684\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.77it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.35it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 finished ! Loss: 0.360 | Loss_weight: 0.360 | sensivity: 0.708 | specitivity: 0.969| Dice score: 0.687\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.89it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.09it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 finished ! Loss: 0.358 | Loss_weight: 0.358 | sensivity: 0.705 | specitivity: 0.969| Dice score: 0.687\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.80it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.13it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 finished ! Loss: 0.359 | Loss_weight: 0.359 | sensivity: 0.712 | specitivity: 0.968| Dice score: 0.686\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.82it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.23it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 finished ! Loss: 0.358 | Loss_weight: 0.358 | sensivity: 0.732 | specitivity: 0.963| Dice score: 0.682\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.81it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.21it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 finished ! Loss: 0.358 | Loss_weight: 0.358 | sensivity: 0.690 | specitivity: 0.973| Dice score: 0.689\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:38<00:00,  8.60it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.10it/s]\n",
      "  0%|          | 0/341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 finished ! Loss: 0.360 | Loss_weight: 0.360 | sensivity: 0.730 | specitivity: 0.964| Dice score: 0.682\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:39<00:00,  8.83it/s]\n",
      "100%|██████████| 34/34 [00:15<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 finished ! Loss: 0.358 | Loss_weight: 0.358 | sensivity: 0.712 | specitivity: 0.968| Dice score: 0.687\n",
      "Current learning rate is: 0.001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "niter = 25\n",
    "\n",
    "requires_grad(net, True)\n",
    "net.train()\n",
    "\n",
    "LIST_DICE_VAL = []\n",
    "LIST_BCE_TRAIN = []\n",
    "LIST_DICE_LOSS_TRAIN = []\n",
    "\n",
    "if IS_TRAINING:\n",
    "    for epoch in range(0,niter):\n",
    "        epoch_loss = 0\n",
    "        epoch_dice = 0\n",
    "        epoch_bounary = 0\n",
    "        epoch_loss_weight = 0\n",
    "        requires_grad(net, True)\n",
    "        net.train()\n",
    "        for i,data in enumerate(tqdm(dataloader)):  \n",
    "            img_data_v = Variable(data['image'])\n",
    "            mask_data_v = Variable(data['mask'])\n",
    "            mask_pred_data_v = Variable(data['mask_pred'])\n",
    "\n",
    "            if use_cuda:\n",
    "                img_data_v = img_data_v.cuda()\n",
    "                mask_data_v = mask_data_v.cuda()\n",
    "                mask_pred_data_v = mask_pred_data_v.cuda()\n",
    "\n",
    "            batchSize = img_data_v.size(0)\n",
    "\n",
    "            net.zero_grad()\n",
    "            data_catted = torch.cat([img_data_v, mask_pred_data_v], 1)\n",
    "            masks_pred = net(data_catted)\n",
    "\n",
    "            masks_probs_flat = masks_pred.view(-1)\n",
    "            true_masks_flat = mask_data_v.view(-1)\n",
    "\n",
    "#             focal_loss_ = focal_loss(masks_probs_flat, true_masks_flat)\n",
    "            ft_loss = focal_tversky_loss(true_masks_flat, masks_probs_flat)\n",
    "            dice_loss_ = dice_loss(masks_probs_flat, true_masks_flat)\n",
    "            loss = ft_loss\n",
    "            epoch_loss_weight += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_dice += dice_loss_.item()\n",
    "            epoch_bounary += 0\n",
    "            loss.backward()\n",
    "\n",
    "            optimizerE.step()        \n",
    "\n",
    "        scheduler.step()\n",
    "        requires_grad(net, False)\n",
    "        net.eval()\n",
    "        dice_list = []\n",
    "        sensivity_list = []\n",
    "        specitivity_list = []\n",
    "        for j_,data in enumerate(tqdm(dataloader_valid)):      \n",
    "            img_data_v = Variable(data['image'])\n",
    "            mask_data_v = Variable(data['mask'])\n",
    "            mask_pred_data_v = Variable(data['mask_pred'])\n",
    "            if use_cuda:\n",
    "                img_data_v = img_data_v.cuda()\n",
    "                mask_data_v = mask_data_v.cuda()\n",
    "                mask_pred_data_v = mask_pred_data_v.cuda()\n",
    "\n",
    "            batchSize = img_data_v.size(0)\n",
    "            data_catted = torch.cat([img_data_v, mask_pred_data_v], 1)\n",
    "            masks_pred = net(data_catted)\n",
    "            masks_probs_flat = masks_pred.view(-1)\n",
    "            true_masks_flat = mask_data_v.view(-1)\n",
    "            masks_probs_flat_np = masks_probs_flat.cpu().numpy()\n",
    "            masks_probs_flat_np = np.where(masks_probs_flat_np > 0.5, 1, 0)\n",
    "            true_masks_flat_np = true_masks_flat.cpu().numpy()\n",
    "            true_masks_flat_np = np.where(true_masks_flat_np > 0.5, 1, 0)\n",
    "\n",
    "            dice_ = dice_loss_np(masks_probs_flat_np.reshape(-1).astype(int), true_masks_flat_np.reshape(-1).astype(int))\n",
    "            dice_list.append(dice_)\n",
    "        \n",
    "            tn_, fp_, fn_, tp_ = confusion_matrix(true_masks_flat_np.reshape(-1).astype(int), masks_probs_flat_np.reshape(-1).astype(int)).ravel()\n",
    "            specificity = tn_ / (tn_+fp_)\n",
    "            sensitivity = tp_ / (tp_+fn_)\n",
    "\n",
    "            sensivity_list.append(sensitivity)\n",
    "            specitivity_list.append(specificity)\n",
    "    \n",
    "\n",
    "        ## checkpoint\n",
    "        if epoch%10==0 or epoch == (niter-1):\n",
    "            torch.save(net.state_dict(),\"%s/net_%03d.pth\"%(outf,epoch+1))\n",
    "\n",
    "        print()\n",
    "        print('Epoch {} finished ! Loss: {:04.3f} | Loss_weight: {:04.3f} | sensivity: {:04.3f} | specitivity: {:04.3f}| Dice score: {:04.3f}'.format(epoch,epoch_loss / i, \n",
    "                                                epoch_loss_weight/i, np.array(sensivity_list).mean(),\n",
    "                                                np.array(specitivity_list).mean(), 1 - np.array(dice_list).mean()))\n",
    "        for param_group in optimizerE.param_groups:\n",
    "            print(\"Current learning rate is: {}\".format(param_group['lr']))\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('./saved_model/net_040.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775 697\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 1200\n",
    "PATCH_SIZE = 128\n",
    "STEP = 64\n",
    "\n",
    "INPUT_DIR_FULL_IMAGE = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/data_full/'\n",
    "INPUT_DIR_MASK_GT_FULL_IMAGE = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/data_full/'\n",
    "INPUT_DIR_MASK_PRED_FULL_IMAGE = '/home/quang/working/fundus_segmentation/data/segmentation_doctor/data_full_mask_pred/'\n",
    "OUTPUT_DIR_MASK_PRED_FULL_IMAGE = './predictions/'\n",
    "\n",
    "list_paths_img = glob.glob(INPUT_DIR_FULL_IMAGE + '*.jpg')\n",
    "list_paths_mask = [x.split('.')[0] + '.labels.tif' for x in list_paths_img]\n",
    "\n",
    "list_paths_img_train, list_paths_img_test, list_paths_mask_train, list_paths_mask_test = train_test_split(list_paths_img, list_paths_mask, \n",
    "                                                                                                          test_size=0.1, random_state=12)\n",
    "\n",
    "list_name_f = [x.split('/')[-1].split('.')[0] for x in list_paths_img_test]\n",
    "\n",
    "print (len(list_paths_img), len(list_paths_img_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_with_res(pred_np, true_np, SIZE = 512):\n",
    "    pred_rescaled = cv2.resize((pred_np*255).astype(np.uint8), (SIZE, SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "    pred_rescaled = np.where(pred_rescaled > 128, 1, 0).reshape(-1).astype(int)\n",
    "    \n",
    "    true_rescaled = cv2.resize((true_np*255).astype(np.uint8), (SIZE, SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "    true_rescaled = np.where(true_rescaled > 128, 1, 0).reshape(-1).astype(int)\n",
    "\n",
    "    return dice_loss_np(pred_rescaled, true_rescaled.reshape(-1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_album_FULL_IMAGE = Compose([\n",
    "    Resize(int(PATCH_SIZE), int(PATCH_SIZE)), \n",
    "], additional_targets = {'image0': 'image', 'mask_pred': 'mask'})\n",
    "\n",
    "test_transform_torch_FULL_IMAGE = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "test_transform_torch_mask_pred_FULL_IMAGE = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "toTensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [05:05<00:00,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score:  0.6250615175252656\n",
      "Sensivity:  0.6615360988014666\n",
      "Specitivity:  0.9970243503297536\n",
      "Accuracy:  0.9948013977920226\n",
      "Jaccard:  0.4719299921313919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "dice_list_whole_image = []\n",
    "sensivity_list_whole_image = []\n",
    "specitivity_list_whole_image = []\n",
    "acc_list = []\n",
    "jacc_list = []\n",
    "\n",
    "for temp_name in tqdm(list_name_f):\n",
    "    img = cv2.imread(INPUT_DIR_FULL_IMAGE + temp_name + '.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #??????\n",
    "    img_rescaled = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    mask_GT = cv2.imread(INPUT_DIR_MASK_GT_FULL_IMAGE + temp_name + '.labels.tif', 0)\n",
    "    mask_GT = np.where(mask_GT > 0, 255, 0).astype(np.uint8)\n",
    "    mask_GT_rescaled = cv2.resize(mask_GT, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "    mask_GT_rescaled = np.where(mask_GT_rescaled > 128, 1, 0).astype(np.uint8)\n",
    "    mask_GT_rescaled = np.expand_dims(mask_GT_rescaled, axis=-1)\n",
    "\n",
    "    mask_pred = cv2.imread(INPUT_DIR_MASK_PRED_FULL_IMAGE + temp_name + '.jpg', 0)\n",
    "    mask_pred_rescaled = cv2.resize(mask_pred, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_CUBIC)\n",
    "    mask_pred_rescaled = np.expand_dims(mask_pred_rescaled, axis=-1)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img_rescaled, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray_mask = np.where(img_gray > 10, 1, 0)\n",
    "    circle = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
    "    cv2.circle(circle, (int(IMG_SIZE/2), int(IMG_SIZE/2)), int(IMG_SIZE/2), 1, thickness=-1)\n",
    "\n",
    "    img_gray_mask = img_gray_mask*circle\n",
    "\n",
    "    mask_predict = np.zeros((IMG_SIZE,IMG_SIZE))\n",
    "    mask_predict_count = np.zeros((IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "    for i in range(0, IMG_SIZE-PATCH_SIZE, STEP):\n",
    "        for j in range(0, IMG_SIZE-PATCH_SIZE, STEP):\n",
    "    #         if img_gray_mask[i:i+PATCH_SIZE, j:j+PATCH_SIZE].sum() > PATCH_SIZE*PATCH_SIZE/2 and mask_cropped[i:i+PATCH_SIZE, j:j+PATCH_SIZE].sum() > 0:\n",
    "            if img_gray_mask[i:i+PATCH_SIZE, j:j+PATCH_SIZE].sum() > PATCH_SIZE*PATCH_SIZE/2 or True:\n",
    "                img_patch = img_rescaled[i:i+PATCH_SIZE, j:j+PATCH_SIZE,:]\n",
    "                mask_GT_patch = mask_GT_rescaled[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
    "                mask_pred_patch = mask_pred_rescaled[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
    "\n",
    "                img_auged = test_album_FULL_IMAGE(image=img_patch, mask=mask_GT_patch, mask_pred=mask_pred_patch)\n",
    "\n",
    "                image_tensor = img_auged['image']\n",
    "                mask_tensor = img_auged['mask']\n",
    "                mask_pred_aug = img_auged['mask_pred']\n",
    "                image_tensor = test_transform_torch_FULL_IMAGE(image_tensor)\n",
    "#                 mask_tensor = toTensor(mask_tensor).float()\n",
    "                mask_tensor = test_transform_torch_mask_pred_FULL_IMAGE(mask_tensor)\n",
    "                mask_pred_tensor = test_transform_torch_mask_pred_FULL_IMAGE(mask_pred_aug).float() #???? mask_pred_tensor = toTensor(mask_pred_aug).float()\n",
    "\n",
    "                image_tensor = image_tensor.cuda()\n",
    "                mask_tensor = mask_tensor.cuda()\n",
    "                mask_pred_tensor = mask_pred_tensor.cuda()\n",
    "\n",
    "                data_catted = torch.cat([image_tensor, mask_pred_tensor], 0)\n",
    "\n",
    "                masks_pred = net(torch.unsqueeze(data_catted, 0))\n",
    "                mask_predict[i:i+PATCH_SIZE, j:j+PATCH_SIZE] += masks_pred.cpu().numpy()[0,0]\n",
    "                mask_predict_count[i:i+PATCH_SIZE, j:j+PATCH_SIZE] += 1\n",
    "\n",
    "    mask_predict_count_temp = np.where(mask_predict_count == 0, 1, mask_predict_count)\n",
    "    mask_predict_avg = mask_predict/mask_predict_count_temp\n",
    "    mask_predict_avg_binary = np.where(mask_predict_avg > 0.5, 1, 0)\n",
    "\n",
    "    dice_list_whole_image.append(dice_with_res(mask_predict_avg_binary, mask_GT_rescaled))\n",
    "\n",
    "    tn_, fp_, fn_, tp_ = confusion_matrix(mask_GT_rescaled.reshape(-1).astype(int), mask_predict_avg_binary.reshape(-1).astype(int)).ravel()\n",
    "    specificity = tn_ / (tn_+fp_)\n",
    "    sensitivity = tp_ / (tp_+fn_)\n",
    "    \n",
    "    jacc = jaccard_score(mask_GT_rescaled.reshape(-1).astype(int), mask_predict_avg_binary.reshape(-1).astype(int))\n",
    "    jacc_list.append(jacc)\n",
    "    sensivity_list_whole_image.append(sensitivity)\n",
    "    specitivity_list_whole_image.append(specificity)\n",
    "    acc_list.append((tp_ + tn_)/ (tp_+tn_+fp_+fn_))\n",
    "    \n",
    "    cv2.imwrite(OUTPUT_DIR_MASK_PRED_FULL_IMAGE + temp_name + '.png', mask_predict_avg_binary*255)\n",
    "    \n",
    "print ('Dice score: ', 1 - np.array(dice_list_whole_image).mean())\n",
    "print ('Sensivity: ', np.array(sensivity_list_whole_image).mean())\n",
    "print ('Specitivity: ', np.array(specitivity_list_whole_image).mean())\n",
    "print ('Accuracy: ', np.array(acc_list).mean())\n",
    "print ('Jaccard: ', np.array(jacc_list).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
